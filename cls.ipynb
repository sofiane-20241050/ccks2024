{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import *\n",
    "def read_json(path: str) -> List[Dict]:\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        return json.loads(file.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(path: str) -> List[Dict]:\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        data = []\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            data.append(json.loads(line))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\"因果\": 0, \"时序\": 1, \"无\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {v: k for k, v in label2id.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata = read_jsonl(path=\"dataset/train.json\")\n",
    "len(traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata = read_jsonl(path = \"dataset/testa.json\")\n",
    "len(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'new-ID': '10290',\n",
       " 'doc': '成都市原市长助理门生涉嫌受贿案侦查终结，移送审查起诉_一号专案_澎湃新闻-ThePape。\\n\\n中新网成都1月5日电，5日，成都市人民检察院官方网站公布了近段时间成都市检察机关查处的4起职务犯罪案件信息。其中，原成都市市长助理、秘书长门生（副厅级）涉嫌受贿一案，由成都市人民检察院侦查终结，移送审查起诉。门生，男，汉族，1959年3月生，四川内江人。2009年门生因抗震救灾有功等原因，兼任成都市市长助理。2013年2月，门生转任成都市市长助理、市政府秘书长，并兼市政府办公厅党组书记，市委党校（行政学院）第一副校（院）长等职迄今。2015年06月10日，成都市纪委发布消息称，经成都市委同意，成都市纪委对成都市市长助理、市政府秘书长门生涉嫌严重违纪违法问题进行立案调查。门生是2014年8月以来，成都继陈争鸣、刘俊林及周鸿德之后落马的第4位市长助理。2015年9月17日，成都市人民检察院依法决定对成都市政府原市长助理、秘书长门生（副厅级）受贿立案侦查。2015年9月25日，经四川省人民检察院决定，依法对门生予以逮捕。此外，成都市检察院还公布了成都武侯区投资促进局副局长岳文婷、成都锦江区三圣街道办事处办公室原主任胡杨、成都市公积金管理中心原党委书记胡旭光的职务犯罪案件信息。',\n",
       " 'events': [{'id': '10290_1',\n",
       "   'event-information': {'trigger': [{'text': '立案侦查',\n",
       "      'start': 422,\n",
       "      'end': 426}],\n",
       "    'event_type': '司法行为_立案调查'}},\n",
       "  {'id': '10290_2',\n",
       "   'event-information': {'trigger': [{'text': '逮捕', 'start': 457, 'end': 459}],\n",
       "    'event_type': '司法行为_拘捕'}}],\n",
       " 'relations': [{'one_event_id': '10290_1',\n",
       "   'other_event_id': '10290_2',\n",
       "   'relation_type': '时序'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = traindata[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'立案侦查'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"doc\"][422:426]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['司法行为_立案调查', '司法行为_拘捕', '突发事件_社会安全_经济安全（抢劫、盗窃等）', '突发事件_社会安全_袭击', '人生_死亡', '突发事件_社会安全_爆炸', '突发事件_事故灾难_交通运输事故', '司法行为_罚款', '司法行为_起诉', '突发事件_社会安全_罢工', '财经/交易_出售', '突发事件_事故灾难_火灾', '突发事件_自然灾害_气象灾害', '组织关系_解雇', '突发事件_事故灾难_公共设施事故', '突发事件_事故灾难_生态污染事件', '突发事件_社会安全_劫持', '人生_生病/检查', '突发事件_事故灾难_工矿商贸安全事件', '竞赛行为_禁赛', '司法行为_举报', '突发事件_公共卫生_疫情', '突发事件_自然灾害_地震灾害', '突发事件_自然灾害_水旱灾害', '财经/交易_降价', '突发事件_自然灾害_地质灾害', '财经/交易_涨价', '交往行为_威胁', '突发事件_社会安全_游行聚集', '产品行为_检验', '突发事件_公共卫生_食品安全', '人生_产子', '组织行为_开幕', '组织行为_闭幕', '产品行为_下架', '突发事件_自然灾害_生物灾害', '移动_运输', '司法行为_出狱', '突发事件_社会安全_民族宗教', '司法行为_入狱', '移动_出行', '组织关系_选举', '产品行为_召回', '交往行为_道歉', '竞赛行为_竞赛', '交往行为_见面', '产品行为_制造', '交往行为_联系', '人生_结婚', '人生_离婚', '财经/交易_股票下跌', '财经/交易_股票上涨', '人生_获奖', '产品行为_发布', '竞赛行为_晋级', '交往行为_感谢', '组织关系_离职', '财经/交易_上市', '财经/交易_收购', '组织关系_裁员', '人生_升学']\n"
     ]
    }
   ],
   "source": [
    "event_types = []\n",
    "for d in traindata:\n",
    "    for evt in d[\"events\"]:\n",
    "        # evt_type = evt[\"event-information\"][\"event_type\"].split(\"_\")[0]\n",
    "        evt_type = evt[\"event-information\"][\"event_type\"]\n",
    "        if evt_type not in event_types:\n",
    "            event_types.append(evt_type)\n",
    "print(event_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(event_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /data/jupyter/root/disk/0_BERTmodels/huggingface/bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at /data/jupyter/root/disk/0_BERTmodels/huggingface/bert-base-chinese and are newly initialized: ['bert.embeddings.history_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "path = \"/data/jupyter/root/disk/0_BERTmodels/huggingface/bert-base-chinese\"\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "model = AutoModel.from_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (history_embeddings): Embedding(13, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'new-ID': '10290',\n",
       " 'doc': '成都市原市长助理门生涉嫌受贿案侦查终结，移送审查起诉_一号专案_澎湃新闻-ThePape。\\n\\n中新网成都1月5日电，5日，成都市人民检察院官方网站公布了近段时间成都市检察机关查处的4起职务犯罪案件信息。其中，原成都市市长助理、秘书长门生（副厅级）涉嫌受贿一案，由成都市人民检察院侦查终结，移送审查起诉。门生，男，汉族，1959年3月生，四川内江人。2009年门生因抗震救灾有功等原因，兼任成都市市长助理。2013年2月，门生转任成都市市长助理、市政府秘书长，并兼市政府办公厅党组书记，市委党校（行政学院）第一副校（院）长等职迄今。2015年06月10日，成都市纪委发布消息称，经成都市委同意，成都市纪委对成都市市长助理、市政府秘书长门生涉嫌严重违纪违法问题进行立案调查。门生是2014年8月以来，成都继陈争鸣、刘俊林及周鸿德之后落马的第4位市长助理。2015年9月17日，成都市人民检察院依法决定对成都市政府原市长助理、秘书长门生（副厅级）受贿立案侦查。2015年9月25日，经四川省人民检察院决定，依法对门生予以逮捕。此外，成都市检察院还公布了成都武侯区投资促进局副局长岳文婷、成都锦江区三圣街道办事处办公室原主任胡杨、成都市公积金管理中心原党委书记胡旭光的职务犯罪案件信息。',\n",
       " 'events': [{'id': '10290_1',\n",
       "   'event-information': {'trigger': [{'text': '立案侦查',\n",
       "      'start': 422,\n",
       "      'end': 426}],\n",
       "    'event_type': '司法行为_立案调查'}},\n",
       "  {'id': '10290_2',\n",
       "   'event-information': {'trigger': [{'text': '逮捕', 'start': 457, 'end': 459}],\n",
       "    'event_type': '司法行为_拘捕'}}],\n",
       " 'relations': [{'one_event_id': '10290_1',\n",
       "   'other_event_id': '10290_2',\n",
       "   'relation_type': '时序'}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = sample[\"events\"]\n",
    "trigger1 = events[0][\"event-information\"][\"trigger\"][0]\n",
    "trigger2 = events[1][\"event-information\"][\"trigger\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'成都市原市长助理门生涉嫌受贿案侦查终结，移送审查起诉_一号专案_澎湃新闻-ThePape。\\n\\n中新网成都1月5日电，5日，成都市人民检察院官方网站公布了近段时间成都市检察机关查处的4起职务犯罪案件信息。其中，原成都市市长助理、秘书长门生（副厅级）涉嫌受贿一案，由成都市人民检察院侦查终结，移送审查起诉。门生，男，汉族，1959年3月生，四川内江人。2009年门生因抗震救灾有功等原因，兼任成都市市长助理。2013年2月，门生转任成都市市长助理、市政府秘书长，并兼市政府办公厅党组书记，市委党校（行政学院）第一副校（院）长等职迄今。2015年06月10日，成都市纪委发布消息称，经成都市委同意，成都市纪委对成都市市长助理、市政府秘书长门生涉嫌严重违纪违法问题进行立案调查。门生是2014年8月以来，成都继陈争鸣、刘俊林及周鸿德之后落马的第4位市长助理。2015年9月17日，成都市人民检察院依法决定对成都市政府原市长助理、秘书长门生（副厅级）受贿立案侦查。2015年9月25日，经四川省人民检察院决定，依法对门生予以逮捕。此外，成都市检察院还公布了成都武侯区投资促进局副局长岳文婷、成都锦江区三圣街道办事处办公室原主任胡杨、成都市公积金管理中心原党委书记胡旭光的职务犯罪案件信息。'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = sample[\"doc\"][(trigger1[\"start\"]-10):trigger1[\"end\"]+10)]\n",
    "text2 = sample[\"doc\"][(trigger1[\"start\"]-10):trigger1[\"end\"]+10)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-11",
   "language": "python",
   "name": "tf-11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
